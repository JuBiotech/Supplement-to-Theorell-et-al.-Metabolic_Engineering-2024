{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'M0',\n",
    "    'M1',\n",
    "    'M2',\n",
    "    'M_M1',\n",
    "    '{M0}',\n",
    "    '{M_M1}',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BM_oaa1.x', 'BM_oaa1_aux.n', 'BM_oaa3.x', 'BM_oaa6_aux.n', 'BM_oga1.x', 'BM_oga1_aux.n', 'BM_pep3_aux.n', 'BM_pga1.x', 'BM_pyr2_aux.n', 'ana1.n', 'emp1.n', 'emp1.x', 'emp2.x', 'emp3.x', 'emp4.x', 'emp5.x', 'emp6.n', 'emp6.x', 'gs1.x', 'gs2.x', 'ppp1.x', 'ppp2.x', 'ppp3.x', 'ppp4.x', 'ppp5.x', 'ppp6.x', 'tca1.n', 'tca1.x', 'tca2.x', 'tca3.x', 'tca4.x', 'tca5b.x', 'tca6.x', 'upt.n']\n"
     ]
    }
   ],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM_oaa1.n\n",
      "BM_oaa6.n\n",
      "BM_oga1.n\n",
      "BM_pep3.n\n",
      "BM_pyr2.n\n",
      "ana1.n\n",
      "emp1.n\n",
      "emp6.n\n",
      "tca1.n\n",
      "upt.n\n"
     ]
    }
   ],
   "source": [
    "for n in net_flux_names:\n",
    "    print(f'{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10)\n",
      "(10, 10000, 10)\n",
      "M0\n",
      "1.00175\n",
      "1.00202\n",
      "1.00140\n",
      "1.00036\n",
      "1.00156\n",
      "1.00074\n",
      "1.00346\n",
      "1.00119\n",
      "1.00113\n",
      "1.00093\n",
      "(100000, 10)\n",
      "(10, 10000, 10)\n",
      "M1\n",
      "1.00081\n",
      "1.00119\n",
      "1.00087\n",
      "1.00115\n",
      "1.00066\n",
      "1.00001\n",
      "1.00005\n",
      "1.00032\n",
      "1.00084\n",
      "1.00012\n",
      "(100000, 10)\n",
      "(10, 10000, 10)\n",
      "M2\n",
      "1.00162\n",
      "1.00139\n",
      "1.00111\n",
      "1.00122\n",
      "1.00087\n",
      "1.00004\n",
      "1.00029\n",
      "1.00013\n",
      "1.00039\n",
      "1.00025\n",
      "(100000, 10)\n",
      "(10, 10000, 10)\n",
      "M_M1\n",
      "1.00070\n",
      "1.00049\n",
      "1.00038\n",
      "1.00031\n",
      "1.00120\n",
      "1.00057\n",
      "1.00867\n",
      "1.00272\n",
      "1.00428\n",
      "1.00106\n",
      "(100000, 10)\n",
      "(10, 10000, 10)\n",
      "{M0}\n",
      "1.00104\n",
      "1.00129\n",
      "1.00055\n",
      "1.00088\n",
      "1.00052\n",
      "1.00007\n",
      "1.00051\n",
      "1.00030\n",
      "1.00023\n",
      "1.00008\n",
      "(100000, 10)\n",
      "(10, 10000, 10)\n",
      "{M_M1}\n",
      "1.00056\n",
      "1.00073\n",
      "1.00052\n",
      "1.00064\n",
      "1.00064\n",
      "1.00058\n",
      "1.00071\n",
      "1.00033\n",
      "1.00053\n",
      "1.00016\n"
     ]
    }
   ],
   "source": [
    "flux_data = []\n",
    "flux_names = []\n",
    "\n",
    "table_single = pd.DataFrame()\n",
    "table_multi = pd.DataFrame()\n",
    "\n",
    "for m in model_names:\n",
    "    columns = pd.read_csv(f'{m}_names.csv', header=None)[0].to_list()\n",
    "    columns = [c.replace('_aux','') for c in columns]\n",
    "    \n",
    "    net_flux_names = [n for n in columns if n.endswith('.n')]\n",
    "    flux_names.append(columns)\n",
    "    d = pd.read_csv(f'{m}_samples.csv', names=columns)\n",
    "    d = d [net_flux_names]\n",
    "    flux_data.append(d)\n",
    "        \n",
    "    s = d.to_numpy()\n",
    "    print(s.shape)\n",
    "    stacked_samples = np.zeros((10, 10000, len(net_flux_names)))\n",
    "    stacked_samples[0,:,:] = s[0:10000,:]\n",
    "    stacked_samples[1,:,:] = s[10000:20000,:]\n",
    "    stacked_samples[2,:,:] = s[20000:30000,:]\n",
    "    stacked_samples[3,:,:] = s[30000:40000,:]\n",
    "    stacked_samples[4,:,:] = s[40000:50000,:]\n",
    "    stacked_samples[5,:,:] = s[50000:60000,:]\n",
    "    stacked_samples[6,:,:] = s[60000:70000,:]\n",
    "    stacked_samples[7,:,:] = s[70000:80000,:]\n",
    "    stacked_samples[8,:,:] = s[80000:90000,:]\n",
    "    stacked_samples[9,:,:] = s[90000:,:]\n",
    "    \n",
    "    print(stacked_samples.shape)\n",
    "    ess = hopsy.ess(stacked_samples)\n",
    "    rhat = hopsy.rhat(stacked_samples)\n",
    "    \n",
    "    print(m)\n",
    "    for r in rhat[0]:\n",
    "        formatted = \"{:.5f}\".format(r)\n",
    "        print(f'{formatted}')\n",
    "        \n",
    "#     print(m)\n",
    "#     for r in ess[0]:\n",
    "#         print(f'{round(r)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
